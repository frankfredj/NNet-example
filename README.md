# NNet-example
A simple example of a neural network with a single hidden layer. Weights are randomly initialized, then calibrated using a small step size.
This piece of code was attached to an article about how neural networks work (http://disconcordia.com/blog)
